MachineData_Optimize:
* Utilize Julia to optimize the best output condition of a machine with certain constraints and variables.
	The most interesting part of creating this code was working on the "correct" constraint equations.

ProcessData_collection:
* This code collect certain data required from thousands of PDFs with NTML security settings. 
	The code quickened my task significantly, from 1 month to 3-4 days. 
	Code is also more accurate, as no human error of copy and paste was involved. 
	I enjoyed producing this code, as I was solving each step without any prior knowledge (how to access url, then finding ntml access,etc.)
	This showed me that I enjoy figuring out challenges by breaking them into smaller steps. 

ProductionData_Analysis:
* This code reflected a few standard step of data cleaning (unique filter, filtering out zeros, qualitatively analyzing data)
	I learned how to diagnose and clean data "intuitively".
	Once I learned the Google Data ANalytics certificate, I realized I was employing many data cleaning tools and tips.
	It was interesting to reflect and connect the similarities and differences between what I did and what I learned.
	I realized that I need to organize many of my data structure better (which are not shown here due to company data copyright).
	This goes the same for my coding. I need better and consistent practice at code-documenting.
